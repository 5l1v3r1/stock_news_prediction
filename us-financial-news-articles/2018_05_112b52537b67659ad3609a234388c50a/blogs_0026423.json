{"organizations": [], "uuid": "6b718517250ead0f48eadab57200496585e95140", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 2}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 1, "shares": 1, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "blogs.wsj.com", "main_image": "", "site_section": "http://blogs.wsj.com/cio/feed/", "section_title": "CIO Journal.", "url": "https://blogs.wsj.com/cio/2018/05/11/bank-of-america-confronts-ais-black-box-with-fraud-detection-effort/", "country": "US", "domain_rank": 387, "title": "Bank of America Confronts AI’s ‘Black Box’ With Fraud Detection Effort", "performance_score": 0, "site": "wsj.com", "participants_count": 1, "title_full": "", "spam_score": 0.0, "site_type": "blogs", "published": "2018-05-11T22:19:00.000+03:00", "replies_count": 0, "uuid": "6b718517250ead0f48eadab57200496585e95140"}, "author": "Sara Castellanos and Kim S. Nash", "url": "https://blogs.wsj.com/cio/2018/05/11/bank-of-america-confronts-ais-black-box-with-fraud-detection-effort/", "ord_in_thread": 0, "title": "Bank of America Confronts AI’s ‘Black Box’ With Fraud Detection Effort", "locations": [], "entities": {"persons": [{"name": "hari gopalkrishnan", "sentiment": "negative"}, {"name": "gopalkrishnan", "sentiment": "none"}], "locations": [{"name": "new york city", "sentiment": "none"}, {"name": "new york", "sentiment": "none"}], "organizations": [{"name": "bank of america", "sentiment": "negative"}, {"name": "bank of america confronts ai’s ‘black box’ with fraud detection effort", "sentiment": "neutral"}, {"name": "u.s. department of defense to uber technologies inc.", "sentiment": "none"}, {"name": "bank of america corp.", "sentiment": "none"}, {"name": "capital one financial corp.", "sentiment": "none"}, {"name": "bank of americas tech summit", "sentiment": "none"}, {"name": "work-bench", "sentiment": "none"}, {"name": "harvard university", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "0 COMMENTS Hari Gopalkrishnan, client-facing platforms technology executive at Bank of America (right) spoke at a panel about artificial intelligence at Bank of Americas Tech Summit, hosted Thursday, May 10, at enterprise technology venture capital fund Work-Bench in New York City. Photo: Work-Bench\nNEW YORK — Bank of America Corp. is in the early stages of experimenting with how artificial intelligence could help improve fraud detection, but first, executives say they need to understand how the algorithms actually work.\nThe bank joins several organizations, ranging from the research arm of the U.S. Department of Defense to Uber Technologies Inc. and Capital One Financial Corp., that are grappling with the opaque nature of advanced AI algorithms. It recently announced they’re working with Harvard University to address topics such as bias in algorithms.\n“We’re not fans of lack of transparency and black boxes, where the answer is just ‘yes’ or ‘no,’” said Hari Gopalkrishnan, client-facing platforms technology executive at Bank of America.\nMr. Gopalkrishnan spoke about the bank’s interest in artificial intelligence at Bank of America’s Tech Summit, hosted Thursday at enterprise technology venture capital fund Work-Bench.\nMore In Explainable AI Facing Growing Concern Over AI, Tech Firms Call for ‘Responsible’ Development Inside Darpa’s Push to Make Artificial Intelligence Explain Itself The bank currently uses analytic models to help employees detect fraud and, for the past few months, has been studying how artificial intelligence could further improve the detection rate, he said.\nIf a customer reports a fraudulent charge, an advanced AI system could one day analyze large datasets and provide an employee with a specific judgment about whether the charge was indeed fraudulent, based on the customer’s past purchase behaviors and other data.\nArtificial intelligence could also be used to detect money laundering, Mr. Gopalkrishnan said.\nBut the problem with advanced artificial intelligence systems, such as deep learning, is that they are not well understood . Deep learning tools include neural networks, software whose structure roughly tries to mimic the human brain’s operations, and while these systems can draw conclusions with unprecedented accuracy and speed, it’s not always clear how the dense web of computations reaches a specific decision.\nAn AI system that makes a judgment about a customer needs to be able to explain itself, Mr. Gopalkrishnan and other executives there say.\n“We want to understand how the decision is made, so that we can stand behind it and say that we’re not disfavoring someone,” he said.\nThere’s no time frame for when an AI system could be deployed to help detect fraud, in part because solving the explainability problem is so important, he said.\nCapital One also is researching ways that AI algorithms could explain the rationale behind their answers , which could have far-reaching impacts in guarding against potential ethical and regulatory breaches as the firm uses more artificial intelligence in banking.\nBank of America in April announced The Council on the Responsible Use of Artificial Intelligence to study the ethics and consequences of AI.\nCathy Bessant, chief operations and technology officer for Bank of America, said it’s an important area of research in part because the technology stands to change how legal, labor, commerce and other constructs work.\n“The scale and pace of development mean that there’s a real risk that AI can change the nature of the workforce much more quickly than reskilling can take place,” she said in a recent interview.\nWhile it’s mainly technology companies that produce AI, other kinds of companies, including banks, consume it, she said. “We thought it was time to ensure balance in the discussion between creators and deployers.”\nBank of America creates its own algorithms and computer models. It also buys some from technology firms. Either way, the bank tests them to make sure they produce intended outcomes before putting them into service with customers or employees, Ms. Bessant said.\n“We are in this [council] because, as AI is a key driver of growth for our future, it’s a worthy investment in getting it right,” she said.\nShare this: ARTIFICIAL INTELLIGENCE BANK OF AMERICA EXPLAINABLE AI Previous What Your CEO Is Reading: Killer AI; Kansans Not In Kansas Anymore; AI Alchemy", "external_links": [], "published": "2018-05-11T22:19:00.000+03:00", "crawled": "2018-05-12T01:00:11.001+03:00", "highlightTitle": ""}
{"organizations": [], "uuid": "86265a010111a14836cc721c20303791d956bbe3", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.cnbc.com", "main_image": "https://fm.cnbc.com/applications/cnbc.com/resources/img/editorial/2018/03/14/105065183-GettyImages-840370370.1910x1000.jpg", "site_section": "", "section_title": "", "url": "https://www.cnbc.com/2018/03/14/allen-institute-ceo-says-a-i-graduates-should-take-oath.html", "country": "US", "domain_rank": 767, "title": "Allen Institute CEO says A.I. graduates should take oath", "performance_score": 0, "site": "cnbc.com", "participants_count": 0, "title_full": "", "spam_score": 0.0, "site_type": "news", "published": "2018-03-14T19:23:00.000+02:00", "replies_count": 0, "uuid": "86265a010111a14836cc721c20303791d956bbe3"}, "author": "Catherine Clifford", "url": "https://www.cnbc.com/2018/03/14/allen-institute-ceo-says-a-i-graduates-should-take-oath.html", "ord_in_thread": 0, "title": "Allen Institute CEO says A.I. graduates should take oath", "locations": [], "entities": {"persons": [{"name": "oren etzioni", "sentiment": "none"}, {"name": "musk", "sentiment": "none"}, {"name": "mark zuckerberg", "sentiment": "none"}, {"name": "harry shum", "sentiment": "none"}, {"name": "zuckerberg", "sentiment": "none"}, {"name": "brad smith", "sentiment": "none"}], "locations": [], "organizations": [{"name": "mins ago cnbc.com", "sentiment": "negative"}, {"name": "allen institute", "sentiment": "negative"}, {"name": "allen institute for arti", "sentiment": "none"}, {"name": "microsoft", "sentiment": "none"}, {"name": "elon musk", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "Exactly how artificial intelligence will affect our lives is under intense debate by some very influential thought leaders, including Elon Musk and Mark Zuckerberg .\nMusk has been a consistent voice warning about the danger of AI , while Zuckerberg has been more optimistic, calling such doomsday scenarios \" pretty irresponsible .\"\nOne certainty about AI, however, is that it will have a profound impact on the future.\nA hippocratic oath for artificial intelligence practitioners \nAs such, the president and chief legal officer of Microsoft, Brad Smith , and the executive vice president of Microsoft's AI and Research group, Harry Shum , propose in their book, \" The Future Computed ,\" that those working in AI could pledge an oath similar in nature to the ones doctors take.\nOne expert in AI has taken the next step forward, drafting an amended version of the popular Hippocratic Oath for those who graduate in the field of AI. The adjusted oath pledges a commitment to use knowledge of AI to create technology for good.\nOren Etzioni is CEO of the Allen Institute for Artificial Intelligence , an organization created by Microsoft co-founder Paul Allen , which does AI research and engineering \" all for the common good ,\" according to its website. Etzioni has also been a professor at the University of Washington's Computer Science department since 1991.\nOren Etzioni, photo courtesy Allen Institute for Artificial Intelligence \n\"In the past, much power and responsibility over life and death was concentrated in the hands of doctors. Now, this ethical burden is increasingly shared by the builders of AI software,\" says Etzioni in a TechCrunch story published Wednesday.\n\"Future AI advances in medicine, transportation, manufacturing, robotics, simulation, augmented reality, virtual reality, military applications, dictate that AI be developed from a higher moral ground today,\" he writes.\nEtzioni's proposed Hippocratic Oath, according to TechCrunch, is as follows:\nI swear to fulfill, to the best of my ability and judgment, this covenant:\nI will respect the hard-won scientific gains of those scientists and engineers in whose steps I walk, and gladly share such knowledge as is mine with those who are to follow.\nI will apply, for the benefit of the humanity, all measures required, avoiding those twin traps of over-optimism and uniformed pessimism.\nI will remember that there is an art to AI as well as science, and that human concerns outweigh technological ones.\nMost especially must I tread with care in matters of life and death. If it is given me to save a life using AI, all thanks. But it may also be within AI's power to take a life; this awesome responsibility must be faced with great humbleness and awareness of my own frailty and the limitations of AI. Above all, I must not play at God nor let my technology do so.\nI will respect the privacy of humans for their personal data are not disclosed to AI systems so that the world may know.\nI will consider the impact of my work on fairness both in perpetuating historical biases, which is caused by the blind extrapolation from past data to future predictions, and in creating new conditions that increase economic or other inequality.\nMy AI will prevent harm whenever it can, for prevention is preferable to cure.\nMy AI will seek to collaborate with people for the greater good, rather than usurp the human role and supplant them.\nI will remember that I am not encountering dry data, mere zeros and ones, but human beings, whose interactions with my AI software may affect the person's freedom, family, or economic stability. My responsibility includes these related problems.\nI will remember that I remain a member of society, with special obligations to all my fellow human beings.\nEtzioni does not imagine that an oath will eliminate nefarious applications of AI. Instead, it's a start, a reminder, a move in the right direction.\n\"I call on our universities to have their students swear this oath as part of their graduation into the field of AI. Of course, an oath is far short of a panacea, but it reminds us of the values we hold dear,\" says Etzioni.\nSee also: \nElon Musk: 'Mark my words â€” A.I. is far more dangerous than nukes' \nFacebook CEO Mark Zuckerberg: Elon Musk's doomsday AI predictions are 'pretty irresponsible' \nElon Musk responds to Harvard professor Steven Pinker's comments on A.I.: 'Humanity is in deep trouble' \nLike this story? Like CNBC Make It on Facebook . \nshow chapters This CEO wants to put a computer chip in your brain      10:35 AM ET Wed, 12 April 2017 | 01:15", "external_links": [], "published": "2018-03-14T19:23:00.000+02:00", "crawled": "2018-03-14T19:27:52.023+02:00", "highlightTitle": ""}
{"organizations": [], "uuid": "7e5929ee26e929ceeab981f1a217210aad93ca79", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 138, "shares": 138, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.cnbc.com", "main_image": "https://fm.cnbc.com/applications/cnbc.com/resources/img/editorial/2016/12/01/104140512-GettyImages-51615686.1910x1000.jpg", "site_section": "http://www.cnbc.com/id/19746125/device/rss/rss.xml", "section_title": "Top News and Analysis (pro)", "url": "https://www.cnbc.com/2018/03/12/youtube-vs-google-autocorrect.html", "country": "US", "domain_rank": 767, "title": "How YouTube search pushes people toward conspiracy theories and extreme content", "performance_score": 1, "site": "cnbc.com", "participants_count": 0, "title_full": "", "spam_score": 0.0, "site_type": "blogs", "published": "2018-03-12T23:41:00.000+02:00", "replies_count": 0, "uuid": "7e5929ee26e929ceeab981f1a217210aad93ca79"}, "author": "", "url": "https://www.cnbc.com/2018/03/12/youtube-vs-google-autocorrect.html", "ord_in_thread": 0, "title": "How YouTube search pushes people toward conspiracy theories and extreme content", "locations": [], "entities": {"persons": [], "locations": [], "organizations": [{"name": "google", "sentiment": "negative"}, {"name": "new york times", "sentiment": "none"}, {"name": "mins ago cnbc.com  youtube", "sentiment": "none"}, {"name": "youtube", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "How YouTube search pushes people toward conspiracy theories and extreme content Google and YouTube autocomplete responses are very different. YouTube's autocomplete continues to push people towards conspiracy theories and extreme content. Published 20 Hours Ago CNBC.com \nYouTube is still struggling to figure out how to keep from recommending divisive content like conspiracy theories. \nOn Monday afternoon, YouTube users on Twitter highlighted problems with the site's autocomplete feature, which automatically suggests search queries after a user starts typing a few letters or a word, as well as its recommendation engine: Tweet \nThe thread was spawned by the New York Times' recent editorial exploring YouTube's role as \"one of the most powerful radicalizing instruments of the 21st century.\" \nThe video site, owned by Alphabet 's Google, has been the subject of several recent investigations showing how it highlights extreme content, like conspiracy theories or hyper-partisan points of view, over more measured videos. \nFor example, YouTube and Google's autocomplete boxes deliver starkly different answers, with the video site recommending controversial or fake points of view on YouTube. \nYouTube results are on the left while Google results are on the right. Both searches were done in Google's \"incognito mode\" to prevent the results from being affected by prior search history. \nWhen The Wall Street Journal asked YouTube about this issue earlier this year, a Google spokesperson said other parts of the company were working with the YouTube team to \" share learnings \" about how to surface more authoritative content. \nGoogle says that its autocomplete feature takes into account factors like \"popularity\" and \"freshness,\" though a representative didn't respond to questions about how YouTube's autocomplete feature differs. \nThe autocomplete and recommendation options are particularly jarring because Google's Chromebook laptops, which include YouTube's app, have become incredibly popular for students , making up more than half of all new laptop shipments for K-12 students in 2016, according to Futuresource Consulting. \nIt's been a rough year for YouTube, which has also struggled with issues of fake news and child exploitation . show chapters", "external_links": [], "published": "2018-03-12T23:41:00.000+02:00", "crawled": "2018-03-13T00:10:30.079+02:00", "highlightTitle": ""}
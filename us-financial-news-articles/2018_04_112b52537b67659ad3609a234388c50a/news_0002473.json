{"organizations": [], "uuid": "dc43e47b4225bb6b43296b685028440848ebde6a", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 3}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 198, "shares": 198, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.wsj.com", "main_image": "https://images.wsj.net/im-5699/social", "site_section": "http://www.wsj.com/xml/rss/3_7014.xml", "section_title": "WSJ.com: US Business", "url": "https://www.wsj.com/articles/tesla-uber-deaths-raise-questions-about-the-perils-of-partly-autonomous-driving-1522661400", "country": "US", "domain_rank": 387, "title": "Tesla, Uber Deaths Raise Questions About the Perils of Partly Autonomous Driving", "performance_score": 1, "site": "wsj.com", "participants_count": 1, "title_full": "", "spam_score": 0.0, "site_type": "news", "published": "2018-04-02T13:30:00.000+03:00", "replies_count": 0, "uuid": "dc43e47b4225bb6b43296b685028440848ebde6a"}, "author": "Tim Higgins", "url": "https://www.wsj.com/articles/tesla-uber-deaths-raise-questions-about-the-perils-of-partly-autonomous-driving-1522661400", "ord_in_thread": 0, "title": "Tesla, Uber Deaths Raise Questions About the Perils of Partly Autonomous Driving", "locations": [], "entities": {"persons": [{"name": "tesla", "sentiment": "negative"}], "locations": [{"name": "u.s.", "sentiment": "none"}, {"name": "ariz.", "sentiment": "none"}, {"name": "calif.", "sentiment": "none"}, {"name": "tempe", "sentiment": "none"}, {"name": "mountain view", "sentiment": "none"}], "organizations": [{"name": "uber technologies inc.", "sentiment": "none"}, {"name": "tesla inc", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "100 COMMENTS Two recent fatal crashes of cars with varying levels of autonomous-driving technology are focusing attention on vehicles that vest control in both humans and machines.\nU.S. investigators are still completing their probes of an Uber Technologies Inc. self-driving vehicle with a safety-operator behind the wheel that hit and killed a pedestrian March 18 in Tempe, Ariz., and of a Tesla Inc. TSLA -5.06% Model X sport-utility with its semiautonomous system engaged that collided with a highway barrier on March 23 near Mountain View, Calif., fatally injuring its driver.\nBut both incidents have a troubling link, autonomous-vehicle specialists say: a human was at the wheel and could have taken control.\n“This is what I’ve called the mushy middle of automation,” said Bryant Walker Smith, a University of South Carolina assistant professor of law and specialist on autonomous cars, referring to vehicles with some automation but still a driver at the wheel. “There will certainly be more incidents,” he said. “It’s dangerous when people feel safer than they actually are.”\nThe scene of a fatal accident involving a self-driving Uber car on the street in Tempe, Ariz., on March 19. Photo: ABC-15/AP Auto makers are gradually rolling out partially automated systems that pass control back and forth between vehicle and driver. General Motors Co. , Volkswagen AG’s Audi brand, and others have or plan to introduce systems that allow the driver to cede control of the car in certain situations, only to resume command at a moment’s notice.\nSuch automation could make driving safer. But some autonomous-vehicle experts and safety advocates worry that as long as the effort is a combination of human and machine, the robot assistance could also give drivers a false sense of confidence to turn their attention elsewhere.\nOthers, such as GM, say driver monitoring ensures a driver remains engaged, while Tesla has developed a series of alerts aimed at keeping hands on the wheel and emphasizes in its manuals that drivers need to remain alert and responsible for driving.\nConcerns about a human driver being lulled into complacency is what led Google to scrap plans for a semiautonomous system and to focus efforts on building a vehicle system capable of driving without a person at the wheel , an effort now under way at the Waymo unit of Alphabet Inc., GOOGL -3.19% also the parent of Google. Waymo has pointed to a 2015 regulatory study that found some drivers took 17 seconds to retake control of a vehicle, a duration that would have allowed the car to travel more than a quarter mile at highway speeds.\nA Jaguar I-PACE self-driving car at its unveiling by Alphabet Inc. subsidiary Waymo in New York City on March 27. Photo: brendan mcdermid/Reuters Auto makers, tech companies and regulators contend robot vehicles promise to ultimately cut traffic fatalities, which surpassed 37,000 in the U.S. in 2016, according to the latest government data. Human error causes 94% of crashes, according to regulators.\nThe companies are pressing to develop new services like driverless taxis and automated long-haul trucking that could collectively create a business opportunity valued in the trillions of dollars, analysts say.\nGM believes services built around driverless cars one day could reap more money than its business today, finance chief Chuck Stevens told analysts in November. He said a robot taxi service could generate 20% to 30% profit margins by 2025, several times more than the 8.8% pretax margin it earned globally last year.\nFew auto makers predict they will sell fully driverless cars anytime soon. Yet, they fear falling behind their rivals if they wait until systems are so advanced they don’t require human drivers, said Mark Wakefield, the leader of AlixPartners LLP’s automotive practice. “You can lose by not participating at all,” he said.\nSo in the meantime, they are outfitting vehicles with semiautonomous features such as automatic braking, adaptive cruise control and lane-keeping systems. In some cases they are on the cusp of rolling out more advanced hands-free driving systems that can handle increasingly complex driving tasks, such as passing slower cars on the highway, while handing control back to the driver when the computer can’t handle a more complicated situation.\nAudi is aiming to release a new system in its sedans that would allow drivers to let go of the wheel and pedal in traffic jams and turn their attention to, say, their email. Audi is “carefully evaluating” consumer acceptance of semiautonomous driving features and is waiting for better legal and regulatory clarity before introducing the system, a spokesman said. \nSachin Lawande, chief executive of automotive supplier Visteon Corp., said in a January interview that by 2020, he expects such technology to be so ubiquitous that it will be hard to sell a mainstream vehicle without such automated features.\nThe Uber self-driving test car that crashed in Tempe was being designed ultimately to be fully autonomous, but a human safety operator was at the wheel in case the robot brain got confused during testing. Video of the collision suggested the driver was looking down seconds before the vehicle struck the pedestrian.\nTesla on Friday said its semiautonomous Autopilot system was active in the seconds before the recent fatal crash . The driver’s hands weren’t on the wheel for six seconds before the SUV collided with a barrier. He took no action despite having five seconds and about 500 feet of unobstructed view of a concrete highway divider, Tesla said.\nThe National Transportation Safety Board, among the U.S. agencies probing the crash, on Sunday released a statement saying it was “unhappy with the release of investigative information by Tesla.” Tesla declined to comment on the agency’s remarks. \nThe NTSB said it would probe all aspects of the crash, including suggestions the driver had expressed previous concerns about Autopilot. Tesla said a thorough search of service records didn’t find evidence the customer ever complained to the company about Autopilot. One concern was raised about navigation working incorrectly, but “Autopilot’s performance is unrelated to navigation,” Tesla said. \nAutopilot isn’t a fully autonomous system, Tesla says, and drivers retain responsibility to stay alert and maintain control of the vehicle, the company says in owners’ manuals.\nThe Palo Alto., Calif., company has been aggressive in deploying semiautonomous driving technology, citing potential safety improvements as too important to delay. In a statement Friday, Tesla said its vehicles had driven the same stretch of highway with Autopilot engaged about 85,000 times since they were first deployed in 2015 without incident.\nAfter a May 2016 fatal crash involving Tesla’s Autopilot system , the NTSB found a hands-on-the-wheel detection system was a poor substitute for measuring driver alertness. One recommendation that emerged from the NTSB probe was for companies to adopt cameras to monitor drivers.\nGM designed its Super Cruise hands-free highway driving system on Cadillac vehicles with an infrared camera mounted on the steering column to detect whether drivers are alert. The technology provides escalating alarms to inattentive drivers, including an audible warning to retake the wheel, before disabling the system.\nHinrich Woebcken, head of Volkswagen’s North American operations, said the industry is still grappling with the safety of having machines make critical decisions. “Technologically, we will always be more on the safer, more on the conservative side,” he said last week at the New York International Auto Show. \nWrite to Tim Higgins at Tim.Higgins@WSJ.com , Mike Spector at mike.spector@wsj.com and Mike Colias at Mike.Colias@wsj.com", "external_links": [], "published": "2018-04-02T13:30:00.000+03:00", "crawled": "2018-04-02T13:52:54.026+03:00", "highlightTitle": ""}
{"organizations": [], "uuid": "463468853af00101af539e748227da065ed0e9fa", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 10, "shares": 10, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.reuters.com", "main_image": "https://s1.reutersmedia.net/resources/r/?m=02&d=20180403&t=2&i=1247699074&w=1200&r=LYNXNPEE321E0", "site_section": "http://feeds.reuters.com/reuters/topNews\r", "section_title": "Reuters: Top News", "url": "https://www.reuters.com/article/us-autos-selfdriving-crashes/in-self-driving-cars-human-drivers-and-standards-come-up-short-experts-idUSKCN1HA2J6", "country": "US", "domain_rank": 408, "title": "In self-driving cars, human drivers and standards come up short: experts", "performance_score": 0, "site": "reuters.com", "participants_count": 0, "title_full": "", "spam_score": 0.0, "site_type": "news", "published": "2018-04-03T22:59:00.000+03:00", "replies_count": 0, "uuid": "463468853af00101af539e748227da065ed0e9fa"}, "author": "", "url": "https://www.reuters.com/article/us-autos-selfdriving-crashes/in-self-driving-cars-human-drivers-and-standards-come-up-short-experts-idUSKCN1HA2J6", "ord_in_thread": 0, "title": "In self-driving cars, human drivers and standards come up short: experts", "locations": [], "entities": {"persons": [{"name": "paul lienert", "sentiment": "none"}, {"name": "nick carey", "sentiment": "none"}], "locations": [{"name": "u.s.", "sentiment": "none"}, {"name": "los angeles", "sentiment": "none"}, {"name": "california", "sentiment": "none"}], "organizations": [{"name": "acura", "sentiment": "none"}, {"name": "los angeles auto show", "sentiment": "none"}, {"name": "reuters", "sentiment": "none"}, {"name": "tesla inc", "sentiment": "none"}, {"name": "uber technologies inc", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "April 3, 2018 / 8:00 PM / Updated 23 minutes ago In self-driving cars, human drivers and standards come up short: experts Nick Carey , Paul Lienert 5 Min Read \n(Reuters) - Autonomous cars should be required to meet standards on their ability to detect potential hazards and better ways are needed to keep their human drivers ready to assume control, U.S. auto safety and technology experts said after fatal crashes involving Uber Technologies Inc and Tesla Inc vehicles. FILE PHOTO: The front end of the test vehicle Acura is using to test its autonomous Automated Drive car is pictured at the 2016 Los Angeles Auto Show in Los Angeles, California, U.S., November 16, 2016. REUTERS/Mike Blake/File Photo \nAutomakers and tech companies rely on human drivers to step in when necessary with self-driving technology. But in the two recent crashes, which involved vehicles using different kinds of technologies, neither of the human drivers took any action before the accidents. \nDriverless cars rely on lidar, which uses laser light pulses to detect road hazards, as well as sensors such as radar and cameras. There are not, however, any standards on the systems, nor do all companies use the same combination of sensors, and some vehicles may have blind spots. \nQueue the music for the human driver - music that drivers often find difficult to hear. \n“Humans don’t have the ability to take over the vehicle as quickly as may be expected” in those situations, said self-driving expert and investor Evangelos Simoudis. \nIn the Uber crash last month, the ride services company was testing a fully driverless system intended for commercial use when the prototype vehicle struck and killed a woman walking across an Arizona road. Video of the crash, taken from inside the vehicle, shows the driver at the wheel, who appears to be looking down and not at the road. Just before the video stops, the driver looks upwards toward the road and suddenly looks shocked. \nIn the Tesla incident last month, which involved a car that any consumer can buy, a Model X vehicle was in semi-autonomous Autopilot mode when it crashed, killing its driver. The driver had received earlier warnings to put his hands on the wheel, Tesla said. \nSome semi-automated cars, like the Tesla, employ different technologies to help drivers stay in their lane or maintain a certain distance behind the vehicle in front. Those systems rely on alerts - beeping noises or a vibrating steering wheel - to get drivers’ attention. “IMMATURE TECHNOLOGY” \nDuke University mechanical engineering professor Missy Cummings said the recent Uber and Tesla crashes show the “technology they are using is immature.” \nTesla says its technology is statistically proven to save lives through better driving. In a response to Reuters on Tuesday, Tesla said drivers have a “responsibility to maintain control of the car” whenever they enable Autopilot and need to be ready to respond to “audible and visual cues.” FILE PHOTO: A roof mounted camera and radar system is shown on Uber's Ford Fusion self driving car during a demonstration of self-driving automotive technology in Pittsburgh, Pennsylvania, U.S., September 13, 2016. REUTERS/Aaron Josefczyk/File Photo \nAn Uber spokesperson said “safety is our primary concern every step of the way.” \nA consumer group, Advocates for Highway and Auto Safety, says a bill on self-driving cars now stalled in the U.S. Senate is an opportunity to improve safety, quite different from the bill’s original intent to quickly allow testing of self-driving cars without human controls on public roads. The group has proposed amending the bill, the AV START Act, to set standards for those vehicles, for instance, requiring a “vision test” for automated vehicles to test what their different sensors actually see. \nThe group believes the bill should also cover semi-automated systems like Tesla’s Autopilot - a lower level of technology than what is included in the current proposed legislation. \nOther groups have also put forth proposals on self-driving cars, including requiring the vehicles and even semi-automated systems to meet performance targets, greater transparency and data from makers and operators of the vehicles, increased regulatory oversight, and better monitoring of and engagement with human drivers. \nOthers want to focus on the human driver. In November, Consumer Reports magazine called on automakers for responsible labeling “to help consumers fully understand” their vehicles’ autonomous functions. \nJake Fisher, Consumer Reports’ head of automotive testing, said human drivers “are bad at paying attention to automation and this technology is not capable of reacting to all types of emergencies. \n“It’s like being a passenger with a toddler driving the car,” he said. \nThe Massachusetts Institute of Technology is doing tests using semi-automated vehicles including models from Tesla, Volvo, Jaguar Land Rover and General Motors Co. The aim is to see how drivers use semi-autonomous technology - some watch the road with their hands above the wheel, others do not - and which warnings get their attention. \n“We just don’t know enough about how drivers use any of these systems in the wild,” said MIT research scientist Bryan Reimer. \nTimothy Carone, an autonomous systems expert and professor at Notre Dame University’s Mendoza College of Business, said autonomous technology’s proponents must “find the right balance so the technology is tested right, but it isn’t hampered or halted.” \n“Because in the long run it will save lives,” he said. Reporting by Nick Carey and Paul Lienert in Detroit; Editing by Leslie Adler", "external_links": [], "published": "2018-04-03T22:59:00.000+03:00", "crawled": "2018-04-03T23:13:55.026+03:00", "highlightTitle": ""}